{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import DtOmitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecisionTree(object):\n",
    "    \"\"\"\n",
    "    DecisionTree class, that represents one Decision Tree\n",
    "\n",
    "    :param max_tree_depth: maximum depth for this tree.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_tree_depth):\n",
    "        self.max_depth = max_tree_depth\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        \"\"\"\n",
    "        :param X: 2 dimensional python list or numpy 2 dimensional array\n",
    "        :param Y: 1 dimensional python list or numpy 1 dimensional array\n",
    "        \"\"\"\n",
    "        if not isinstance(X,list):\n",
    "            X = X.tolist()\n",
    "        if not isinstance(Y,list):\n",
    "            Y= Y.tolist()\n",
    "        data=[x+y for x,y in zip(X,Y)]\n",
    "        self.trees=build_tree(data,0,self.max_depth)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        :param X: 2 dimensional python list or numpy 2 dimensional array\n",
    "        :return: Y - 1 dimension python list with labels\n",
    "        \"\"\"\n",
    "        Y=[]\n",
    "        for x in X:\n",
    "            tree=self.trees\n",
    "            while not tree.is_leaf:\n",
    "                if x[tree.column] >= tree.value:\n",
    "                    tree=tree.true_branch\n",
    "                else:\n",
    "                    tree=tree.false_branch\n",
    "            Y.append(max(tree.current_results,key=tree.current_results.get))\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class RandomForest(object):\n",
    "    \"\"\"\n",
    "    RandomForest a class, that represents Random Forests.\n",
    "\n",
    "    :param num_trees: Number of trees in the random forest\n",
    "    :param max_tree_depth: maximum depth for each of the trees in the forest.\n",
    "    :param ratio_per_tree: ratio of points to use to train each of\n",
    "        the trees.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_trees, max_tree_depth, ratio_per_tree=0.5):\n",
    "        self.num_trees = num_trees\n",
    "        self.max_tree_depth = max_tree_depth\n",
    "        self.ratio_per_tree=ratio_per_tree\n",
    "        self.trees = None\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        \"\"\"\n",
    "        :param X: 2 dimensional python list or numpy 2 dimensional array\n",
    "        :param Y: 1 dimensional python list or numpy 1 dimensional array\n",
    "        \"\"\"\n",
    "        self.trees = []\n",
    "        for _ in range(self.num_trees):\n",
    "            indices=np.arange(Y.shape[0])\n",
    "            np.random.shuffle(indices)\n",
    "            X=X[indices]\n",
    "            Y=Y[indices]\n",
    "            test_len=int(self.ratio_per_tree*len(X))\n",
    "            X_train=X[:test_len]\n",
    "            Y_train=Y[:test_len]\n",
    "            tree=DecisionTree(self.max_tree_depth)\n",
    "            tree.fit(X_train,Y_train)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        :param X: 2 dimensional python list or numpy 2 dimensional array\n",
    "        :return: (Y, conf), tuple with Y being 1 dimension python\n",
    "        list with labels, and conf being 1 dimensional list with\n",
    "        confidences for each of the labels.\n",
    "        \"\"\"\n",
    "        predicts=[tree.predict(X) for tree in self.trees]\n",
    "        predicts=[[predicts[i][j] for i in range(len(predicts))] for j in range(len(predicts[0]))]\n",
    "        Y=[]\n",
    "        conf=[]\n",
    "        for r in predicts:\n",
    "            results = defaultdict(np.float64)\n",
    "            count=0\n",
    "            for key in r:\n",
    "                results[key]+=1\n",
    "                count+=1\n",
    "            Y.append(max(results,key=results.get))\n",
    "            conf.append(results[Y[-1]]/count)\n",
    "        return (Y, conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def sigmoid(s):\n",
    "    return 1 - 1 / (1 + np.exp(s)) if abs(s) < 10 else 0 if s < 0 else 1\n",
    "\n",
    "\n",
    "def normalized_gradient(X, Y,beta,l):\n",
    "    \"\"\"\n",
    "    :param X: data matrix (2 dimensional np.array)\n",
    "    :param Y: response variables (1 dimensional np.array)\n",
    "    :param beta: value of beta (1 dimensional np.array)\n",
    "    :param l: regularization parameter lambda\n",
    "    :return: normalized gradient, i.e. gradient normalized according to data\n",
    "    \"\"\"\n",
    "    gr = l * beta\n",
    "    s = 0\n",
    "    for i in range(X.shape[0]):\n",
    "        s += X[i] * Y[i] * (1 - sigmoid(Y[i] * beta.T.dot(X[i])))\n",
    "    gr -= s\n",
    "    s = 0\n",
    "    for i in range(X.shape[0]):\n",
    "        s += Y[i] * (1 - sigmoid(Y[i] * beta.T.dot(X[i])))\n",
    "    gr[0] -= s\n",
    "    return gr / X.shape[0]\n",
    "\n",
    "\n",
    "def gradient_descent(xx, yy,l,epsilon,max_steps,step_size,beta):\n",
    "    \"\"\"\n",
    "    Implement gradient descent using full value of the gradient.\n",
    "    :param X: data matrix (2 dimensional np.array)\n",
    "    :param Y: response variables (1 dimensional np.array)\n",
    "    :param l: regularization parameter lambda\n",
    "    :param epsilon: approximation strength\n",
    "    :param max_steps: maximum number of iterations before algorithm will\n",
    "        terminate.\n",
    "    :return: value of beta (1 dimensional np.array)\n",
    "    \"\"\"\n",
    "    X = xx.copy()\n",
    "    Y = yy.copy()\n",
    "    gr = np.zeros(X.shape[1])\n",
    "\n",
    "    v = np.var(X, axis=0, dtype=float) ** 0.5\n",
    "    m = np.mean(X, axis=0, dtype=float)\n",
    "    for i in range(1, X.shape[1]):\n",
    "        for j in range(X.shape[0]):\n",
    "            if v[i] != 0:\n",
    "                X[j][i] -= m[i]\n",
    "                X[j][i] /= v[i]\n",
    "    l = np.array([l / v[_] ** 2 if v[_] != 0 else 0 for _ in range(X.shape[1])])\n",
    "\n",
    "    for s in range(max_steps):\n",
    "        old = beta.copy()\n",
    "        gr = step_size * normalized_gradient(X, Y,beta,l)\n",
    "        beta -= gr\n",
    "        if ((beta - old) ** 2).sum() / ((beta ** 2).sum()) < epsilon ** 2:\n",
    "            break\n",
    "        pass\n",
    "    for i in range(X.shape[1]):\n",
    "        if i == 0:\n",
    "            beta[0] = beta[0] - np.sum(\n",
    "                np.array([m[i] * beta[i] / v[i] if v[i] != 0 else 0 for i in range(1, m.shape[0])]))\n",
    "        else:\n",
    "            beta[i] = beta[i] / v[i] if v[i] != 0 else 0\n",
    "    return beta\n",
    "\n",
    "\n",
    "class logistic(object):\n",
    "    def __init__(self,epsilon=1e-6, l=1, step_size=1e-4, max_steps=1000):\n",
    "        self.epsilon=epsilon\n",
    "        self.step_size=step_size\n",
    "        self.max_steps=max_steps\n",
    "        self.l=l\n",
    "    def fit(self,xx,yy):\n",
    "        \"\"\"\n",
    "        :param xx: 2 dimensional python list or numpy 2 dimensional array\n",
    "        :param yy: 1 dimensional python list or numpy 1 dimensional array\n",
    "        \"\"\"\n",
    "        self.beta=np.random.normal(0,1,xx.shape[1])\n",
    "        self.beta=gradient_descent(xx,yy,epsilon=self.epsilon,l=self.l,step_size=self.step_size,max_steps=self.max_steps,beta=self.beta)\n",
    "    def predict(self,X):\n",
    "        \"\"\"\n",
    "        :param X: 2 dimensional python list or numpy 2 dimensional array\n",
    "        :return: (Y, conf), tuple with Y being 1 dimension python\n",
    "        list with labels, and conf being 1 dimensional list with\n",
    "        confidences for each of the labels.\n",
    "        \"\"\"\n",
    "        return [1 if self.beta.dot(x)>0 else 0 for x in X]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter num :0\n",
      "\tDecision Tree Accuracy =  0.769230769231  ( 0.0 )\n",
      "\tRandom Forest Tree Accuracy =  0.769230769231  ( 0.0 )\n",
      "\tLogistic Reg. Accuracy =  0.730769230769  ( 0.0 )\n",
      "iter num :1\n",
      "\tDecision Tree Accuracy =  0.769230769231  ( 0.0 )\n",
      "\tRandom Forest Tree Accuracy =  0.807692307692  ( 0.0384615384615 )\n",
      "\tLogistic Reg. Accuracy =  0.730769230769  ( 0.0 )\n",
      "iter num :2\n",
      "\tDecision Tree Accuracy =  0.820512820513  ( 0.0725237724294 )\n",
      "\tRandom Forest Tree Accuracy =  0.820512820513  ( 0.0362618862147 )\n",
      "\tLogistic Reg. Accuracy =  0.794871794872  ( 0.0906547155367 )\n",
      "iter num :3\n",
      "\tDecision Tree Accuracy =  0.817307692308  ( 0.0630522935029 )\n",
      "\tRandom Forest Tree Accuracy =  0.798076923077  ( 0.0499630040645 )\n",
      "\tLogistic Reg. Accuracy =  0.788461538462  ( 0.0792904928003 )\n",
      "iter num :4\n",
      "\tDecision Tree Accuracy =  0.807692307692  ( 0.0595843591724 )\n",
      "\tRandom Forest Tree Accuracy =  0.8  ( 0.0448534761142 )\n",
      "\tLogistic Reg. Accuracy =  0.784615384615  ( 0.0713355268884 )\n",
      "iter num :5\n",
      "\tDecision Tree Accuracy =  0.794871794872  ( 0.0614850195297 )\n",
      "\tRandom Forest Tree Accuracy =  0.807692307692  ( 0.0444115591684 )\n",
      "\tLogistic Reg. Accuracy =  0.788461538462  ( 0.0656855818331 )\n",
      "iter num :6\n",
      "\tDecision Tree Accuracy =  0.802197802198  ( 0.0596856070945 )\n",
      "\tRandom Forest Tree Accuracy =  0.818681318681  ( 0.0491443511538 )\n",
      "\tLogistic Reg. Accuracy =  0.791208791209  ( 0.0611842237674 )\n",
      "iter num :7\n",
      "\tDecision Tree Accuracy =  0.798076923077  ( 0.0568853825298 )\n",
      "\tRandom Forest Tree Accuracy =  0.817307692308  ( 0.0461137646472 )\n",
      "\tLogistic Reg. Accuracy =  0.788461538462  ( 0.0576923076923 )\n",
      "iter num :8\n",
      "\tDecision Tree Accuracy =  0.803418803419  ( 0.0557196786769 )\n",
      "\tRandom Forest Tree Accuracy =  0.816239316239  ( 0.043581363364 )\n",
      "\tLogistic Reg. Accuracy =  0.794871794872  ( 0.0573350763461 )\n",
      "iter num :9\n",
      "\tDecision Tree Accuracy =  0.8  ( 0.0538461538462 )\n",
      "\tRandom Forest Tree Accuracy =  0.815384615385  ( 0.0414243446703 )\n",
      "\tLogistic Reg. Accuracy =  0.807692307692  ( 0.0666173387526 )\n",
      "iter num :10\n",
      "\tDecision Tree Accuracy =  0.797202797203  ( 0.0520967287614 )\n",
      "\tRandom Forest Tree Accuracy =  0.804195804196  ( 0.0530271010074 )\n",
      "\tLogistic Reg. Accuracy =  0.807692307692  ( 0.0635171402958 )\n",
      "iter num :11\n",
      "\tDecision Tree Accuracy =  0.791666666667  ( 0.053151038307 )\n",
      "\tRandom Forest Tree Accuracy =  0.807692307692  ( 0.0520771692605 )\n",
      "\tLogistic Reg. Accuracy =  0.810897435897  ( 0.0617351291162 )\n",
      "iter num :12\n",
      "\tDecision Tree Accuracy =  0.772189349112  ( 0.0846174535271 )\n",
      "\tRandom Forest Tree Accuracy =  0.798816568047  ( 0.0587261338499 )\n",
      "\tLogistic Reg. Accuracy =  0.798816568047  ( 0.0725907937656 )\n",
      "iter num :13\n",
      "\tDecision Tree Accuracy =  0.763736263736  ( 0.0870493380096 )\n",
      "\tRandom Forest Tree Accuracy =  0.791208791209  ( 0.0628874897926 )\n",
      "\tLogistic Reg. Accuracy =  0.796703296703  ( 0.0703640026092 )\n",
      "iter num :14\n",
      "\tDecision Tree Accuracy =  0.758974358974  ( 0.0859643826371 )\n",
      "\tRandom Forest Tree Accuracy =  0.784615384615  ( 0.0655728812951 )\n",
      "\tLogistic Reg. Accuracy =  0.789743589744  ( 0.0727952285466 )\n",
      "iter num :15\n",
      "\tDecision Tree Accuracy =  0.766826923077  ( 0.0886168682268 )\n",
      "\tRandom Forest Tree Accuracy =  0.786057692308  ( 0.0637359306902 )\n",
      "\tLogistic Reg. Accuracy =  0.793269230769  ( 0.0717941563609 )\n",
      "iter num :16\n",
      "\tDecision Tree Accuracy =  0.764705882353  ( 0.0863886112762 )\n",
      "\tRandom Forest Tree Accuracy =  0.787330316742  ( 0.0620421230806 )\n",
      "\tLogistic Reg. Accuracy =  0.796380090498  ( 0.0707533745299 )\n",
      "iter num :17\n",
      "\tDecision Tree Accuracy =  0.762820512821  ( 0.0843137592177 )\n",
      "\tRandom Forest Tree Accuracy =  0.786324786325  ( 0.0604364770245 )\n",
      "\tLogistic Reg. Accuracy =  0.797008547009  ( 0.0688087272996 )\n",
      "iter num :18\n",
      "\tDecision Tree Accuracy =  0.765182186235  ( 0.082674404278 )\n",
      "\tRandom Forest Tree Accuracy =  0.783400809717  ( 0.0601183903033 )\n",
      "\tLogistic Reg. Accuracy =  0.797570850202  ( 0.0670159731063 )\n",
      "iter num :19\n",
      "\tDecision Tree Accuracy =  0.763461538462  ( 0.0809293285096 )\n",
      "\tRandom Forest Tree Accuracy =  0.778846153846  ( 0.0618681074698 )\n",
      "\tLogistic Reg. Accuracy =  0.798076923077  ( 0.0653563287229 )\n",
      "iter num :20\n",
      "\tDecision Tree Accuracy =  0.767399267399  ( 0.0809183957303 )\n",
      "\tRandom Forest Tree Accuracy =  0.778388278388  ( 0.0604118040384 )\n",
      "\tLogistic Reg. Accuracy =  0.798534798535  ( 0.0638141076564 )\n",
      "iter num :21\n",
      "\tDecision Tree Accuracy =  0.770979020979  ( 0.0807419806906 )\n",
      "\tRandom Forest Tree Accuracy =  0.783216783217  ( 0.0630341132074 )\n",
      "\tLogistic Reg. Accuracy =  0.800699300699  ( 0.0631310142842 )\n",
      "iter num :22\n",
      "\tDecision Tree Accuracy =  0.769230769231  ( 0.0793918225449 )\n",
      "\tRandom Forest Tree Accuracy =  0.780936454849  ( 0.062569521518 )\n",
      "\tLogistic Reg. Accuracy =  0.797658862876  ( 0.0633688806739 )\n",
      "iter num :23\n",
      "\tDecision Tree Accuracy =  0.766025641026  ( 0.079225686502 )\n",
      "\tRandom Forest Tree Accuracy =  0.780448717949  ( 0.0612967676247 )\n",
      "\tLogistic Reg. Accuracy =  0.798076923077  ( 0.0620670408046 )\n",
      "iter num :24\n",
      "\tDecision Tree Accuracy =  0.770769230769  ( 0.0810288866601 )\n",
      "\tRandom Forest Tree Accuracy =  0.784615384615  ( 0.0634323942403 )\n",
      "\tLogistic Reg. Accuracy =  0.801538461538  ( 0.0631331831652 )\n",
      "iter num :25\n",
      "\tDecision Tree Accuracy =  0.772189349112  ( 0.0797720045131 )\n",
      "\tRandom Forest Tree Accuracy =  0.788461538462  ( 0.0651055653392 )\n",
      "\tLogistic Reg. Accuracy =  0.804733727811  ( 0.0639354520266 )\n",
      "iter num :26\n",
      "\tDecision Tree Accuracy =  0.767806267806  ( 0.0814087296993 )\n",
      "\tRandom Forest Tree Accuracy =  0.790598290598  ( 0.0648109012312 )\n",
      "\tLogistic Reg. Accuracy =  0.804843304843  ( 0.062742779332 )\n",
      "iter num :27\n",
      "\tDecision Tree Accuracy =  0.766483516484  ( 0.0802367135523 )\n",
      "\tRandom Forest Tree Accuracy =  0.793956043956  ( 0.0659912755465 )\n",
      "\tLogistic Reg. Accuracy =  0.803571428571  ( 0.0619656240035 )\n",
      "iter num :28\n",
      "\tDecision Tree Accuracy =  0.770557029178  ( 0.0817346362766 )\n",
      "\tRandom Forest Tree Accuracy =  0.79575596817  ( 0.0655392525231 )\n",
      "\tLogistic Reg. Accuracy =  0.803713527851  ( 0.0608925213965 )\n",
      "iter num :29\n",
      "\tDecision Tree Accuracy =  0.765384615385  ( 0.0850513245673 )\n",
      "\tRandom Forest Tree Accuracy =  0.79358974359  ( 0.0654850912263 )\n",
      "\tLogistic Reg. Accuracy =  0.803846153846  ( 0.0598733047633 )\n",
      "iter num :30\n",
      "\tDecision Tree Accuracy =  0.760545905707  ( 0.0877654550066 )\n",
      "\tRandom Forest Tree Accuracy =  0.792803970223  ( 0.0645638304281 )\n",
      "\tLogistic Reg. Accuracy =  0.803970223325  ( 0.0589036102753 )\n",
      "iter num :31\n",
      "\tDecision Tree Accuracy =  0.762019230769  ( 0.0867718540759 )\n",
      "\tRandom Forest Tree Accuracy =  0.790865384615  ( 0.0644571522971 )\n",
      "\tLogistic Reg. Accuracy =  0.808894230769  ( 0.0641313537113 )\n",
      "iter num :32\n",
      "\tDecision Tree Accuracy =  0.764568764569  ( 0.086655619093 )\n",
      "\tRandom Forest Tree Accuracy =  0.792540792541  ( 0.0641766895009 )\n",
      "\tLogistic Reg. Accuracy =  0.812354312354  ( 0.0661158722782 )\n",
      "iter num :33\n",
      "\tDecision Tree Accuracy =  0.763574660633  ( 0.0855625479518 )\n",
      "\tRandom Forest Tree Accuracy =  0.796380090498  ( 0.0669622108007 )\n",
      "\tLogistic Reg. Accuracy =  0.814479638009  ( 0.0662706720175 )\n",
      "iter num :34\n",
      "\tDecision Tree Accuracy =  0.764835164835  ( 0.0846510557036 )\n",
      "\tRandom Forest Tree Accuracy =  0.794505494505  ( 0.0668977198032 )\n",
      "\tLogistic Reg. Accuracy =  0.814285714286  ( 0.0653268744954 )\n",
      "iter num :35\n",
      "\tDecision Tree Accuracy =  0.764957264957  ( 0.083470192242 )\n",
      "\tRandom Forest Tree Accuracy =  0.791666666667  ( 0.0680665403256 )\n",
      "\tLogistic Reg. Accuracy =  0.813034188034  ( 0.0648373133363 )\n",
      "iter num :36\n",
      "\tDecision Tree Accuracy =  0.769230769231  ( 0.0862347407566 )\n",
      "\tRandom Forest Tree Accuracy =  0.7920997921  ( 0.067190696928 )\n",
      "\tLogistic Reg. Accuracy =  0.81288981289  ( 0.0639609981826 )\n",
      "iter num :37\n",
      "\tDecision Tree Accuracy =  0.769230769231  ( 0.0850925083279 )\n",
      "\tRandom Forest Tree Accuracy =  0.789473684211  ( 0.0681978968742 )\n",
      "\tLogistic Reg. Accuracy =  0.811740890688  ( 0.0634995430824 )\n",
      "iter num :38\n",
      "\tDecision Tree Accuracy =  0.771203155819  ( 0.0848699407256 )\n",
      "\tRandom Forest Tree Accuracy =  0.789940828402  ( 0.0673794510948 )\n",
      "\tLogistic Reg. Accuracy =  0.812623274162  ( 0.0629157313915 )\n",
      "iter num :39\n",
      "\tDecision Tree Accuracy =  0.772115384615  ( 0.0839957645452 )\n",
      "\tRandom Forest Tree Accuracy =  0.790384615385  ( 0.066589575743 )\n",
      "\tLogistic Reg. Accuracy =  0.814423076923  ( 0.0631328902738 )\n",
      "iter num :40\n",
      "\tDecision Tree Accuracy =  0.772983114447  ( 0.083146415783 )\n",
      "\tRandom Forest Tree Accuracy =  0.792682926829  ( 0.0673595612421 )\n",
      "\tLogistic Reg. Accuracy =  0.818011257036  ( 0.0663592464684 )\n",
      "iter num :41\n",
      "\tDecision Tree Accuracy =  0.771978021978  ( 0.0824023184889 )\n",
      "\tRandom Forest Tree Accuracy =  0.792124542125  ( 0.0666488020986 )\n",
      "\tLogistic Reg. Accuracy =  0.815934065934  ( 0.0668999761642 )\n",
      "iter num :42\n",
      "\tDecision Tree Accuracy =  0.772808586762  ( 0.0816162055064 )\n",
      "\tRandom Forest Tree Accuracy =  0.790697674419  ( 0.0665151786854 )\n",
      "\tLogistic Reg. Accuracy =  0.814847942755  ( 0.0664911182113 )\n",
      "iter num :43\n",
      "\tDecision Tree Accuracy =  0.773601398601  ( 0.080850736885 )\n",
      "\tRandom Forest Tree Accuracy =  0.789335664336  ( 0.0663587635547 )\n",
      "\tLogistic Reg. Accuracy =  0.813811188811  ( 0.0660818347991 )\n",
      "iter num :44\n",
      "\tDecision Tree Accuracy =  0.773504273504  ( 0.0799499441618 )\n",
      "\tRandom Forest Tree Accuracy =  0.788888888889  ( 0.0656841916473 )\n",
      "\tLogistic Reg. Accuracy =  0.81452991453  ( 0.0655171552025 )\n",
      "iter num :45\n",
      "\tDecision Tree Accuracy =  0.774247491639  ( 0.0792331621437 )\n",
      "\tRandom Forest Tree Accuracy =  0.788461538462  ( 0.0650295296166 )\n",
      "\tLogistic Reg. Accuracy =  0.813545150502  ( 0.0651369454969 )\n",
      "iter num :46\n",
      "\tDecision Tree Accuracy =  0.777414075286  ( 0.0812746907884 )\n",
      "\tRandom Forest Tree Accuracy =  0.791325695581  ( 0.0672028319727 )\n",
      "\tLogistic Reg. Accuracy =  0.815875613748  ( 0.0663504150593 )\n",
      "iter num :47\n",
      "\tDecision Tree Accuracy =  0.777243589744  ( 0.0804321159701 )\n",
      "\tRandom Forest Tree Accuracy =  0.791666666667  ( 0.0665401906796 )\n",
      "\tLogistic Reg. Accuracy =  0.815705128205  ( 0.0656660296428 )\n",
      "iter num :48\n",
      "\tDecision Tree Accuracy =  0.779434850863  ( 0.081041817891 )\n",
      "\tRandom Forest Tree Accuracy =  0.794348508634  ( 0.0684285548437 )\n",
      "\tLogistic Reg. Accuracy =  0.817111459969  ( 0.0657187933719 )\n",
      "iter num :49\n",
      "\tDecision Tree Accuracy =  0.779230769231  ( 0.0802400245418 )\n",
      "\tRandom Forest Tree Accuracy =  0.793846153846  ( 0.0678320236463 )\n",
      "\tLogistic Reg. Accuracy =  0.813846153846  ( 0.068956722557 )\n",
      "Decision Tree Accuracy =  0.779230769231  ( 0.0802400245418 )\n",
      "Random Forest Tree Accuracy =  0.793846153846  ( 0.0678320236463 )\n",
      "Logistic Reg. Accuracy =  0.813846153846  ( 0.068956722557 )\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def accuracy_score(Y_true, Y_predict):\n",
    "    c=0.\n",
    "    for i in range(len(Y_true)):\n",
    "        if Y_true[i]==Y_predict[i]:\n",
    "            c+=1\n",
    "    return c/len(Y_true)\n",
    "\n",
    "def evaluate_performance():\n",
    "    '''\n",
    "    Evaluate the performance of decision trees and logistic regression,\n",
    "    average over 1,000 trials of 10-fold cross validation\n",
    "\n",
    "    Return:\n",
    "      a matrix giving the performance that will contain the following entries:\n",
    "      stats[0,0] = mean accuracy of decision tree\n",
    "      stats[0,1] = std deviation of decision tree accuracy\n",
    "      stats[1,0] = mean accuracy of logistic regression\n",
    "      stats[1,1] = std deviation of logistic regression accuracy\n",
    "\n",
    "    ** Note that your implementation must follow this API**\n",
    "    '''\n",
    "\n",
    "    # Load Data\n",
    "    stats = np.zeros((3, 2))\n",
    "    filename = 'SPECTF.dat'\n",
    "    data = np.loadtxt(filename, delimiter=',')\n",
    "    X = data[:, 1:]\n",
    "    y = np.array([data[:, 0]]).T\n",
    "    n, d = X.shape\n",
    "    num_folds=10\n",
    "    num_trials=50\n",
    "    all_accuracies=[]\n",
    "    rf_all_accuracies=[]\n",
    "    l_all_accuracies=[]\n",
    "    for trial in range(num_trials):\n",
    "        idx = np.arange(n)\n",
    "        np.random.seed(13)\n",
    "        np.random.shuffle(idx)\n",
    "        X = X[idx]\n",
    "        y = y[idx]\n",
    "\n",
    "        Xtrain = X[:n-n//num_folds, :]  # train on first 100 instances\n",
    "        Xtest = X[n-n//num_folds:, :]\n",
    "        ytrain = y[:n-n//num_folds, :]  # test on remaining instances\n",
    "        ytest = y[n-n//num_folds:, :]\n",
    "\n",
    "        # train the decision tree\n",
    "        classifier = DecisionTree(5)\n",
    "        classifier.fit(Xtrain, ytrain)\n",
    "        # output predictions on the remaining data\n",
    "        y_pred = classifier.predict(Xtest)\n",
    "        accuracy = accuracy_score(ytest, y_pred)\n",
    "        all_accuracies.append(accuracy)\n",
    "\n",
    "        rf_classifier=RandomForest(5,100,0.3)\n",
    "        rf_classifier.fit(Xtrain,ytrain)\n",
    "        rf_y_pred=rf_classifier.predict(Xtest)[0]\n",
    "        rf_accuracy=accuracy_score(ytest,rf_y_pred)\n",
    "        rf_all_accuracies.append(rf_accuracy)\n",
    "\n",
    "        l_classifier=logistic()\n",
    "        l_classifier.fit(Xtest,ytest)\n",
    "\n",
    "        l_y_pred=l_classifier.predict(Xtest)\n",
    "        l_accuracy=accuracy_score(ytest,l_y_pred)\n",
    "        l_all_accuracies.append(l_accuracy)\n",
    "        print('iter num :{0}'.format(trial))\n",
    "        \n",
    "        meanDecisionTreeAccuracy = np.mean(all_accuracies)\n",
    "        stddevDecisionTreeAccuracy = np.std(all_accuracies)\n",
    "        meanLogisticRegressionAccuracy = np.mean(l_all_accuracies)\n",
    "        stddevLogisticRegressionAccuracy = np.std(l_all_accuracies)\n",
    "        meanRandomForestAccuracy = np.mean(rf_all_accuracies)\n",
    "        stddevRandomForestAccuracy = np.std(rf_all_accuracies)\n",
    "\n",
    "    \n",
    "        stats[0, 0] = meanDecisionTreeAccuracy\n",
    "        stats[0, 1] = stddevDecisionTreeAccuracy\n",
    "        stats[1, 0] = meanRandomForestAccuracy\n",
    "        stats[1, 1] = stddevRandomForestAccuracy\n",
    "        stats[2, 0] = meanLogisticRegressionAccuracy\n",
    "        stats[2, 1] = stddevLogisticRegressionAccuracy\n",
    "        \n",
    "        \n",
    "        print (\"\\tDecision Tree Accuracy = \", stats[0, 0], \" (\", stats[0, 1], \")\" )\n",
    "        print (\"\\tRandom Forest Tree Accuracy = \", stats[1, 0], \" (\", stats[1, 1], \")\" )\n",
    "        print (\"\\tLogistic Reg. Accuracy = \", stats[2, 0], \" (\", stats[2, 1], \")\")\n",
    "\n",
    "    # compute the training accuracy of the model\n",
    "    meanDecisionTreeAccuracy = np.mean(all_accuracies)\n",
    "\n",
    "    stddevDecisionTreeAccuracy = np.std(all_accuracies)\n",
    "    meanLogisticRegressionAccuracy = np.mean(l_all_accuracies)\n",
    "    stddevLogisticRegressionAccuracy = np.std(l_all_accuracies)\n",
    "    meanRandomForestAccuracy = np.mean(rf_all_accuracies)\n",
    "    stddevRandomForestAccuracy = np.std(rf_all_accuracies)\n",
    "\n",
    "    # make certain that the return value matches the API specification\n",
    "    stats = np.zeros((3, 2))\n",
    "    stats[0, 0] = meanDecisionTreeAccuracy\n",
    "    stats[0, 1] = stddevDecisionTreeAccuracy\n",
    "    stats[1, 0] = meanRandomForestAccuracy\n",
    "    stats[1, 1] = stddevRandomForestAccuracy\n",
    "    stats[2, 0] = meanLogisticRegressionAccuracy\n",
    "    stats[2, 1] = stddevLogisticRegressionAccuracy\n",
    "    return stats\n",
    "\n",
    "\n",
    "# Do not modify from HERE...\n",
    "if __name__ == \"__main__\":\n",
    "    stats = evaluate_performance()\n",
    "    print (\"Decision Tree Accuracy = \", stats[0, 0], \" (\", stats[0, 1], \")\" )\n",
    "    print (\"Random Forest Tree Accuracy = \", stats[1, 0], \" (\", stats[1, 1], \")\" )\n",
    "    print (\"Logistic Reg. Accuracy = \", stats[2, 0], \" (\", stats[2, 1], \")\")\n",
    "# ...to HERE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'SPECTF.dat'\n",
    "data = np.loadtxt(filename, delimiter=',')\n",
    "X = data[:, 1:]\n",
    "y = np.array([data[:, 0]]).T\n",
    "n, d = X.shape\n",
    "num_folds=10\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = np.arange(n)\n",
    "np.random.seed(10)\n",
    "np.random.shuffle(idx)\n",
    "X = X[idx]\n",
    "y = y[idx]\n",
    "\n",
    "Xtrain = X[:n-n//num_folds, :]  # train on first 100 instances\n",
    "Xtest = X[n-n//num_folds:, :]\n",
    "ytrain = y[:n-n//num_folds, :]  # test on remaining instances\n",
    "ytest = y[n-n//num_folds:, :]\n",
    "\n",
    "rf_classifier=RandomForest(15,100,0.3)\n",
    "rf_classifier.fit(Xtrain,ytrain)\n",
    "\n",
    "l_classifier=logistic()\n",
    "l_classifier.fit(Xtest,ytest)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[ 58.  63.  80.  71.  76.  70.  70.  71.  64.  63.  74.  78.  77.  75.  62.\n",
      "  61.  62.  56.  71.  52.  82.  71.  84.  85.  71.  71.  57.  47.  42.  39.\n",
      "  70.  70.  50.  70.  50.  46.  58.  60.  76.  73.  82.  77.  65.  66.] \n",
      "Y=[ 0.]\n"
     ]
    }
   ],
   "source": [
    "idx=-9\n",
    "print(\"X={0} \\nY={1}\".format(X[idx],y[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.0], [0.66666666666666663])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classifier.predict([X[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_classifier.predict([X[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
